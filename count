#!/usr/bin/env python3
"""
count
  counts lines in files and standard input

usage:
  - counts number of lines in stdin if supplied, and also in files from args
  - if args supplied, gives "filename: count" for each, and also for stdin
  - for single file or stdin only, no filename printed, only count

desc:
  - experiment to determine python's speed compared to other languages
  - 4.7x processor usage (user+sys) over C version (wc -l), python-3.13
  - not very fast! using mmap supposedly doubles, but still... unimpressive

"""
__url__     = 'https://github.com/smemsh/utilpy/'
__author__  = 'Scott Mcdermott <scott@smemsh.net>'
__license__ = 'GPL-2.0'
__devskel__ = '0.8.1'

from sys import exit, hexversion
if hexversion < 0x030900f0: exit("minpython: %s" % hexversion)

import argparse

from sys import argv, stdin, stdout, stderr
from select import select

from os.path import basename
from os import (
    access,
    getenv, unsetenv,
    isatty, dup,
    R_OK,
    close as osclose,
    EX_OK as EXIT_SUCCESS,
    EX_SOFTWARE as EXIT_FAILURE,
)

###

def err(*args, **kwargs):
    print(*args, file=stderr, **kwargs)

def bomb(*args, **kwargs):
    err(*args, **kwargs)
    exit(EXIT_FAILURE)

###

def process_args():

    global args

    def usagex(*args, **kwargs):
        nonlocal p
        p.print_help(file=stderr)
        print(file=stderr)
        bomb(*args, **kwargs)

    def addarg(p, vname, help=None, /, **kwargs):
        p.add_argument(vname, help=help, **kwargs)

    def addargs(*args, **kwargs):
        addarg(*args, nargs='*', **kwargs)

    p = argparse.ArgumentParser(
        prog            = invname,
        description     = __doc__.strip(),
        allow_abbrev    = False,
        formatter_class = argparse.RawTextHelpFormatter,
    )
    addargs(p, 'files', 'files to count besides stdin', default=[])

    args = p.parse_args(args)

    files = []
    if infile: files += [infile]
    if args.files: files += args.files

    return files

###

def countlines_chunks(file):
    lines = 0
    buf = b''
    sz = 64 * 1024  # see performance tables at EOF
    while buf := file.read(sz):
        lines += buf.count(b'\n')
    return lines


def countlines_loop(file):
    lines = 0
    for _ in file:
        lines += 1
    return lines


def count(files):
    multi = len(files) > 1
    for file in files:
        if isinstance(file, str):
            # filename strings were given in the argument vector
            name = file
            try: file = open(name, 'rb')
            except FileNotFoundError:
                print("{}: {}: nsfod".format(invname, name))
                exit(EXIT_FAILURE)
        else:
            # stdin comes as BufferedReader, give a pseudonym for output
            name = '/dev/stdin'

        out = str(countlines_chunks(file))
        if multi: out = f"{name}: {out}"

        print(out)


def main():

    if debug == 1:
        breakpoint()

    files = process_args()

    try: subprogram = globals()[invname]
    except (KeyError, TypeError):
        from inspect import trace
        if len(trace()) == 1: bomb('unimplemented')
        else: raise

    return subprogram(files)

###

if __name__ == "__main__":

    invname = basename(argv[0])
    args = argv[1:]

    # move stdin, pdb needs stdio fds itself
    stdinfd = stdin.fileno()
    if isatty(stdinfd):
        infile = None
    else:
        try:
            if select([stdin], [], [])[0]:
                infile = open(dup(stdinfd), 'rb')
                osclose(stdinfd)  # cpython bug 73582
                try: stdin = open('/dev/tty')
                except: pass  # no ctty, but then pdb would not be in use
        except KeyboardInterrupt:
            bomb("interrupted")

    from bdb import BdbQuit
    if debug := int(getenv('DEBUG') or 0):
        import pdb
        from pprint import pp
        err('debug: enabled')
        unsetenv('DEBUG')  # otherwise forked children hang

    try: main()
    except BdbQuit: bomb("debug: stop")
    except SystemExit: raise
    except KeyboardInterrupt: bomb("interrupted")
    except:
        from traceback import print_exc
        print_exc(file=stderr)
        if debug: pdb.post_mortem()
        else: bomb("aborting...")
    finally:  # cpython bug 55589
        try: stdout.flush()
        finally:
            try: stdout.close()
            finally:
                try: stderr.flush()
                except: pass
                finally: stderr.close()

### EOF ######################################################################
#
# testfile: 2086680000 line 19G /usr/share/dict/words compilation
#
# best c, user+sys = 9.17 (1.0x)
# best py, user+sys = 70.69 (4.7x)
# naive js, user+sys = 135.98 (9.0x)
# naive py, user+sys = 302.54 (20.1x)
#
# glibc-wc    14.53 real    0.49 user      8.68  sys <-- best
# pyio-64k    42.10 real    28.59 user     7.78  sys <-- best-py-cat
# pyio-text   156.73 real   145.81 user    9.49  sys
#
# # pyio-buf bytes.count() chunks, read from stdin, supplied by cat
# 512         49.99 real    39.38 user     9.51  sys
# 1k          47.08 real    35.64 user     9.72  sys
# 2k          45.98 real    33.48 user    10.01  sys
# 4k          43.88 real    31.74 user     9.22  sys
# 8k          42.27 real    29.78 user     8.55  sys
# 16k         43.08 real    29.24 user     8.70  sys
# 32k         42.98 real    29.29 user     8.01  sys
# 64k         42.10 real    28.59 user     7.78  sys <-- best-py-cat
# 128k        42.10 real    28.22 user     7.90  sys
# 256k        57.13 real    29.43 user     8.91  sys
# 512k        57.14 real    28.88 user     9.11  sys
# 1M          54.99 real    27.43 user     9.53  sys
# 128M        44.13 real    24.00 user    16.35  sys
#
# # python print(sum(1 for l in f)):
# sum-file   142.87 real   133.64 user     8.97  sys
#
# # pyio-buf supplied by dd in same-size buffers on stdin:
# dd-bs-1M    39.11 real    29.09 user     4.66  sys <-- best-py-dd
#
# # js: loop on process.stdin.on('data') buffers counting newlines:
# # for (let i = 0; i < buf.length; i++) if (buf[i] === 10) lines++
# nodejs      78.32 real    57.66 user    15.49  sys
#
# todo: different algorithm for regular file vs stdin
# todo: try using mmap() on regular files
# todo: embed other langs via ffi? but then needs build/pkg
# todo: multiprocess chunks for larger seekable files
# todo: one process per file
# testfile: 2086680000 line 19G /usr/share/dict/words compilation
#
# best c, user+sys = 9.17 (1.0x)
# best py, user+sys = 70.69 (4.7x)
# naive js, user+sys = 135.98 (9.0x)
# naive py, user+sys = 302.54 (20.1x)
#
# glibc-wc    14.53 real    0.49 user      8.68  sys <-- best
# pyio-64k    42.10 real    28.59 user     7.78  sys <-- best-py-cat
# pyio-text   156.73 real   145.81 user    9.49  sys
#
# # pyio-buf bytes.count() chunks, read from stdin, supplied by cat
# 512         49.99 real    39.38 user     9.51  sys
# 1k          47.08 real    35.64 user     9.72  sys
# 2k          45.98 real    33.48 user    10.01  sys
# 4k          43.88 real    31.74 user     9.22  sys
# 8k          42.27 real    29.78 user     8.55  sys
# 16k         43.08 real    29.24 user     8.70  sys
# 32k         42.98 real    29.29 user     8.01  sys
# 64k         42.10 real    28.59 user     7.78  sys <-- best-py-cat
# 128k        42.10 real    28.22 user     7.90  sys
# 256k        57.13 real    29.43 user     8.91  sys
# 512k        57.14 real    28.88 user     9.11  sys
# 1M          54.99 real    27.43 user     9.53  sys
# 128M        44.13 real    24.00 user    16.35  sys
#
# # python print(sum(1 for l in f)):
# sum-file   142.87 real   133.64 user     8.97  sys
#
# # pyio-buf supplied by dd in same-size buffers on stdin:
# dd-bs-1M    39.11 real    29.09 user     4.66  sys <-- best-py-dd
#
# # js: loop on process.stdin.on('data') buffers counting newlines:
# # for (let i = 0; i < buf.length; i++) if (buf[i] === 10) lines++
# nodejs      78.32 real    57.66 user    15.49  sys
#
# todo: different algorithm for regular file vs stdin
# todo: try using mmap() on regular files
# todo: embed other langs via ffi? but then needs build/pkg
# todo: multiprocess chunks for larger seekable files
# todo: one process per file
